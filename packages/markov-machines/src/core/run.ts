import type { Machine } from "../types/machine.js";
import type { RunOptions, MachineStep, RunResult, SuspendedInstanceInfo } from "../executor/types.js";
import type { Instance, ActiveLeafInfo } from "../types/instance.js";
import type { Command, Resume } from "../types/commands.js";
import type { MachineMessage, MessageSource } from "../types/messages.js";
import type { YieldReason } from "../executor/types.js";
import { getActiveLeaves, isWorkerInstance, getSuspendedInstances, findInstanceById, clearSuspension } from "../types/instance.js";
import { userMessage } from "../types/messages.js";
import { isCommand, isResume } from "../types/commands.js";
import { runCommand } from "./commands.js";


/** Check if packStates has any entries */
const hasPackStates = (ps?: Record<string, unknown>): boolean =>
  ps !== undefined && Object.keys(ps).length > 0;

// ============================================================================
// Parallel Execution Helpers
// ============================================================================

/**
 * Flattened result from executor.run() + tree metadata for parallel merging.
 * Exported for use by voice package.
 */
export interface LeafResult<AppMessage = unknown> {
  /** Index path to this leaf in the tree */
  leafIndex: number[];
  /** Whether this is a worker instance */
  isWorker: boolean;
  /** Instance ID for attribution */
  instanceId: string;
  /** Updated instance from executor */
  instance: Instance;
  /** History generated by this leaf */
  history: MachineMessage<AppMessage>[];
  /** Why this leaf yielded */
  yieldReason: YieldReason;
  /** Updated pack states (only from non-worker) */
  packStates?: Record<string, unknown>;
  /** Cede content if yielded via cede (string or MachineMessage[]) */
  cedeContent?: string | MachineMessage<AppMessage>[];
}

/**
 * Result of merging all leaf results.
 * Exported for use by voice package.
 */
export interface MergedResult<AppMessage = unknown> {
  /** Updated instance tree */
  instance: Instance;
  /** All history from all leaves */
  history: MachineMessage<AppMessage>[];
  /** Overall yield reason (tool_use if any leaf needs more work) */
  yieldReason: YieldReason;
  /** Whether any leaf ceded */
  hasCede: boolean;
  /** Cede contents from ceded leaves */
  cedeContents: Array<{ instanceId: string; content: string | MachineMessage<AppMessage>[] | undefined }>;
}

/**
 * Update a leaf instance at the given index path.
 */
function updateLeafAtIndex(
  root: Instance,
  indices: number[],
  updater: (leaf: Instance) => Instance,
): Instance {
  if (indices.length === 0) return updater(root);

  const [head, ...rest] = indices;
  const children = root.children ?? [];
  const updated = children.map((c, i) => i === head ? updateLeafAtIndex(c, rest, updater) : c);

  return {
    ...root,
    children: updated.length === 0 ? undefined : updated,
  };
}

/**
 * Remove a leaf instance at the given index path.
 */
function removeLeafAtIndex(root: Instance, indices: number[]): Instance {
  const children = root.children ?? [];

  if (indices.length === 1) {
    const [idx] = indices;
    const filtered = children.filter((_, i) => i !== idx);
    return {
      ...root,
      children: filtered.length === 0 ? undefined : filtered,
    };
  }

  const [head, ...rest] = indices;
  const updated = children.map((c, i) => i === head ? removeLeafAtIndex(c, rest) : c);

  return {
    ...root,
    children: updated.length === 0 ? undefined : updated,
  };
}

/**
 * Wrap messages with source instance metadata.
 */
function wrapMessages<AppMessage>(
  messages: MachineMessage<AppMessage>[],
  instanceId: string,
): MachineMessage<AppMessage>[] {
  return messages.map(msg => {
    const existing = msg.metadata;
    const existingSource = existing?.source;
    if (existingSource?.instanceId && existingSource.instanceId !== instanceId) {
      console.warn(
        `[wrapMessages] Overwriting source.instanceId: ${existingSource.instanceId} -> ${instanceId}`
      );
    }
    const newSource: MessageSource = { ...existingSource, instanceId };
    return {
      ...msg,
      metadata: { ...existing, source: newSource },
    };
  }) as MachineMessage<AppMessage>[];
}

/**
 * Update an instance in the tree by ID.
 */
function updateInstanceById(
  root: Instance,
  targetId: string,
  updater: (inst: Instance) => Instance,
): Instance {
  if (root.id === targetId) {
    return updater(root);
  }

  const children = root.children;
  if (!children || children.length === 0) {
    return root;
  }

  return {
    ...root,
    children: children.map((c) => updateInstanceById(c, targetId, updater)),
  };
}

/**
 * Merge results from parallel leaf execution.
 * Processes in descending index order so removals don't invalidate later indices.
 * Exported for use by voice package.
 */
export function mergeLeafResults<AppMessage>(
  root: Instance,
  results: LeafResult<AppMessage>[],
): MergedResult<AppMessage> {
  let instance = root;
  const allMessages: MachineMessage<AppMessage>[] = [];
  const cedeContents: Array<{ instanceId: string; content: string | MachineMessage<AppMessage>[] | undefined }> = [];
  let hasCede = false;
  let overallYieldReason: YieldReason = "end_turn";
  const packStateUpdates: Record<string, unknown> = {};

  // Sort descending by leaf index (process later/deeper indices first)
  const sorted = [...results].sort((a, b) => {
    for (let i = Math.max(a.leafIndex.length, b.leafIndex.length) - 1; i >= 0; i--) {
      if ((a.leafIndex[i] ?? -1) !== (b.leafIndex[i] ?? -1)) {
        return (b.leafIndex[i] ?? -1) - (a.leafIndex[i] ?? -1);
      }
    }
    return 0;
  });

  for (const leaf of sorted) {
    const { leafIndex, isWorker, instanceId, history, yieldReason, packStates, cedeContent } = leaf;

    // Only non-worker can update pack states
    // Note: Only one non-worker leaf can exist at a time (validated at lines 439-445),
    // so pack state conflicts between leaves cannot occur. This assignment is safe.
    if (!isWorker && packStates) {
      Object.assign(packStateUpdates, packStates);
    }

    // Worker end_turn without cede -> warning (but don't propagate as machine end_turn)
    if (isWorker && yieldReason === "end_turn") {
      console.warn(
        `[runMachine] Worker instance ${instanceId} returned end_turn without ceding. ` +
        `This is unexpected - worker nodes should cede to return control to parent. ` +
        `Treating as if worker work is complete (not propagating end_turn to machine).`
      );
      // Continue processing - don't let worker end_turn affect machine state
      continue;
    }

    // Cede -> remove leaf
    if (yieldReason === "cede") {
      instance = removeLeafAtIndex(instance, leafIndex);
      cedeContents.push({ instanceId, content: cedeContent });
      allMessages.push(...wrapMessages(history, instanceId));
      hasCede = true;
      continue;
    }

    // Normal -> update leaf
    instance = updateLeafAtIndex(instance, leafIndex, () => leaf.instance);
    allMessages.push(...wrapMessages(history, instanceId));

    if (yieldReason === "tool_use" || yieldReason === "max_tokens") {
      overallYieldReason = "tool_use";
    }
  }

  // Apply pack states to root
  if (Object.keys(packStateUpdates).length > 0) {
    instance = { ...instance, packStates: { ...instance.packStates, ...packStateUpdates } };
  }

  return { instance, history: allMessages, yieldReason: overallYieldReason, hasCede, cedeContents };
}

/**
 * Run the machine by draining its queue and executing.
 * Yields MachineStep for each inference call or command execution.
 * Continues until there's a text response or max steps exceeded.
 *
 * Use machine.enqueue() to add messages before calling runMachine:
 * - Regular messages (user, assistant) are added to history and sent to the model
 * - Command messages are processed with higher precedence
 * - System messages (with Resume) are used for internal control flow
 *
 * @typeParam AppMessage - The application message type for structured outputs (defaults to unknown).
 */
export async function* runMachine<AppMessage = unknown>(
  machine: Machine<AppMessage>,
  options?: RunOptions<AppMessage>,
): AsyncGenerator<MachineStep<AppMessage>> {
  // Drain queue
  const queuedMessages = machine.queue.splice(0, machine.queue.length);

  // FIRST: Process all command messages (higher precedence)
  const commandMessages = queuedMessages.filter(msg => msg.role === "command");
  const nonCommandMessages = queuedMessages.filter(msg => msg.role !== "command");

  for (const msg of commandMessages) {
    if (Array.isArray(msg.items)) {
      const commandItem = msg.items.find(isCommand) as Command | undefined;
      if (commandItem) {
        // Process Command
        const { machine: updatedMachine, result, replyMessages } = await runCommand<AppMessage>(
          machine,
          commandItem.name,
          commandItem.input,
          commandItem.instanceId,
        );

        const targetInstanceId = commandItem.instanceId ?? updatedMachine.instance.id;

        // If command returned reply messages, enqueue them for next iteration
        if (replyMessages) {
          if (typeof replyMessages === "string") {
            // String becomes a userMessage
            machine.enqueue([userMessage<AppMessage>(replyMessages, { instanceId: targetInstanceId })]);
          } else {
            // Array of MachineMessages is enqueued directly
            machine.enqueue(replyMessages);
          }
        }

        const commandMsg = result.success
          ? `[Command: ${commandItem.name} executed]`
          : `[Command: ${commandItem.name} failed - ${result.error}]`;

        // done: false only if there are still items in the queue
        yield {
          instance: updatedMachine.instance,
          history: [userMessage(commandMsg, { instanceId: targetInstanceId })],
          yieldReason: "end_turn",
          done: machine.queue.length === 0,
        };
        return;
      }
    }
  }

  // SECOND: Check for Resume in system messages
  for (const msg of nonCommandMessages) {
    if (msg.role === "system" && Array.isArray(msg.items)) {
      const resumeItem = msg.items.find(isResume) as Resume | undefined;
      if (resumeItem) {
        // Process Resume
        const targetInstance = findInstanceById(machine.instance, resumeItem.instanceId);
        if (!targetInstance) {
          throw new Error(`Instance not found: ${resumeItem.instanceId}`);
        }
        if (!targetInstance.suspended) {
          throw new Error(`Instance ${resumeItem.instanceId} is not suspended`);
        }
        if (targetInstance.suspended.suspendId !== resumeItem.suspendId) {
          throw new Error(
            `Suspend ID mismatch: expected ${targetInstance.suspended.suspendId}, got ${resumeItem.suspendId}`
          );
        }

        // Clear the suspended field
        const updatedInstance = updateInstanceById(
          machine.instance,
          resumeItem.instanceId,
          clearSuspension,
        );

        yield {
          instance: updatedInstance,
          history: [userMessage(`[Resumed instance ${resumeItem.instanceId}]`)],
          yieldReason: "command",
          done: false,
        };
        return;
      }
    }
  }

  // Normal execution - continue with non-command messages
  let currentInstance = machine.instance;

  // Base history from before this run, plus queued messages (excluding command messages already processed)
  const baseHistory: MachineMessage<AppMessage>[] = [...(machine.history ?? []), ...nonCommandMessages];
  let currentHistory: MachineMessage<AppMessage>[] = baseHistory;

  // Track input messages for the current step (user messages go on first step only)
  let stepInputMessages: MachineMessage<AppMessage>[] = [...nonCommandMessages];

  const maxSteps = options?.maxSteps ?? 50;
  let steps = 0;
  let tokenRecoveryAttempted = false;

  while (steps < maxSteps) {
    steps++;

    // Get all active leaves for parallel execution
    const activeLeaves = getActiveLeaves(currentInstance);
    if (activeLeaves.length === 0) {
      // Check if all leaves are suspended
      const suspendedInstances = getSuspendedInstances(currentInstance);
      if (suspendedInstances.length > 0) {
        // All leaves are suspended - yield awaiting_resume
        const suspendedInfo: SuspendedInstanceInfo[] = suspendedInstances.map((inst) => ({
          instanceId: inst.id,
          suspendId: inst.suspended!.suspendId,
          reason: inst.suspended!.reason,
          metadata: inst.suspended!.metadata,
        }));
        yield {
          instance: currentInstance,
          history: [],
          yieldReason: "awaiting_resume",
          done: true,
          suspendedInstances: suspendedInfo,
        };
        return;
      }
      throw new Error("No active instances found");
    }

    // Validate: max 1 non-worker leaf
    const nonWorkerLeaves = activeLeaves.filter(l => !l.isWorker);
    if (nonWorkerLeaves.length > 1) {
      throw new Error(
        `Invalid state: ${nonWorkerLeaves.length} non-worker active leaves. ` +
        `At most one instance can receive user input per step.`
      );
    }

    if (options?.debug) {
      console.log(`[runMachine] Step ${steps}/${maxSteps}`);
      console.log(`[runMachine]   Active leaves: ${activeLeaves.length} (${nonWorkerLeaves.length} non-worker)`);
    }

    // Execute all leaves in parallel
    const results = await Promise.all(
      activeLeaves.map(async ({ path, leafIndex, isWorker }) => {
        const leaf = path[path.length - 1]!;
        const ancestors = path.slice(0, -1);

        if (options?.debug) {
          const instructions = leaf.node.instructions;
          console.log(`[runMachine]   Leaf ${leafIndex.join('.')}: ${instructions.slice(0, 40)}... (worker: ${isWorker})`);
        }

        const result = await machine.charter.executor.run(
          machine.charter,
          leaf,
          ancestors,
          "",
          { ...options, history: currentHistory, currentStep: steps, maxSteps },
        );

        // Flatten RunResult into LeafResult
        return {
          leafIndex,
          isWorker,
          instanceId: leaf.id,
          ...result,
        } as LeafResult<AppMessage>;
      })
    );

    if (options?.debug) {
      for (const r of results) {
        console.log(`[runMachine]   Leaf ${r.leafIndex.join('.')} result: ${r.yieldReason}, ${r.history.length} history`);
      }
    }

    // Process all results through unified path
    const merged = mergeLeafResults(currentInstance, results);
    currentInstance = merged.instance;
    machine.instance = currentInstance;  // Keep machine.instance in sync for external access

    // Combine input messages (first step only) with model output for this step's history
    const stepHistory = [...stepInputMessages, ...merged.history];
    // Clear input messages for subsequent steps (they don't have new user input)
    stepInputMessages = [];

    // Single-leaf cede: yield explicit cede step (backwards compatible)
    // Multi-leaf cede (worker cedes while primary continues): just add to history
    if (activeLeaves.length === 1 && merged.hasCede) {
      const cedeInfo = merged.cedeContents[0];
      const cedeContent = cedeInfo?.content;

      // Yield cede step (never final - parent needs to respond)
      yield {
        instance: currentInstance,
        history: stepHistory,
        yieldReason: "cede",
        done: false,
        cedeContent,
      };

      // Prepare for parent's turn with cede content
      if (cedeContent !== undefined) {
        if (typeof cedeContent === "string") {
          // String content becomes a user message
          const cedeMessage = userMessage<AppMessage>(cedeContent, { instanceId: cedeInfo!.instanceId });
          currentHistory = [...baseHistory, cedeMessage];
        } else {
          // Message[] content is appended directly
          currentHistory = [...baseHistory, ...cedeContent];
        }
      } else {
        currentHistory = baseHistory;
      }
      continue;
    }

    // Multi-leaf cede: add cede contents as messages for parent context
    // NOTE: When one leaf cedes while siblings continue, the cede content is added
    // to shared history. This means sibling context may see messages from the ceding
    // branch. This is a known limitation - revisit if isolation is needed.
    if (merged.hasCede && merged.cedeContents.length > 0) {
      for (const { instanceId, content } of merged.cedeContents) {
        if (content !== undefined) {
          if (typeof content === "string") {
            // String content becomes a user message
            const cedeMessage = userMessage<AppMessage>(content, { instanceId });
            currentHistory = [...currentHistory, cedeMessage];
          } else {
            // Message[] content is appended directly
            currentHistory = [...currentHistory, ...content];
          }
        }
      }
    }

    // Handle max_tokens recovery for primary (non-worker) leaf
    // Worker max_tokens is treated as tool_use (keep running) by mergeLeafResults
    const primaryResult = results.find(r => !r.isWorker);
    if (primaryResult?.yieldReason === "max_tokens") {
      if (!tokenRecoveryAttempted) {
        tokenRecoveryAttempted = true;
        if (options?.debug) {
          console.log(`[runMachine] max_tokens hit, attempting recovery...`);
        }

        // Yield the partial step (not final)
        yield {
          instance: currentInstance,
          history: stepHistory,
          yieldReason: "max_tokens",
          done: false,
        };

        // Add recovery message and continue
        const recoveryMessage = userMessage<AppMessage>(
          `[System: Your response was cut off due to length limits. Please provide a brief summary of your findings and respond to the user now. Do not use any tools - just give your final answer.]`
        );
        currentHistory = [...currentHistory, ...merged.history, recoveryMessage];
        continue;
      } else {
        // Recovery already attempted, treat as final
        yield {
          instance: currentInstance,
          history: stepHistory,
          yieldReason: "max_tokens",
          done: true,
        };
        return;
      }
    }

    // Yield the merged step
    const isFinal = merged.yieldReason === "end_turn";
    yield {
      instance: currentInstance,
      history: stepHistory,
      yieldReason: merged.yieldReason,
      done: isFinal,
    };

    if (isFinal) {
      return;
    }

    // Not final - continue to next step
    currentHistory = [...currentHistory, ...(merged.history as MachineMessage<AppMessage>[])];
  }

  throw new Error(`Max steps (${maxSteps}) exceeded`);
}

/**
 * Run the machine to completion, returning only the final step.
 * Convenience wrapper for cases that don't need step-by-step control.
 *
 * @typeParam AppMessage - The application message type for structured outputs (defaults to unknown).
 */
export async function runMachineToCompletion<AppMessage = unknown>(
  machine: Machine<AppMessage>,
  options?: RunOptions<AppMessage>,
): Promise<MachineStep<AppMessage>> {
  let lastStep: MachineStep<AppMessage> | null = null;
  for await (const step of runMachine(machine, options)) {
    lastStep = step;
  }
  if (!lastStep) {
    throw new Error("No steps produced");
  }
  return lastStep;
}
