import type { Machine } from "../types/machine.js";
import type { RunOptions, MachineStep, RunResult, SuspendedInstanceInfo } from "../executor/types.js";
import type { Instance, ActiveLeafInfo } from "../types/instance.js";
import type { Resume } from "../types/commands.js";
import type {
  MachineMessage,
  MessageSource,
  InstanceMessage,
  ConversationMessage,
  InstancePayload,
} from "../types/messages.js";
import type { YieldReason } from "../executor/types.js";
import { getActiveLeaves, isWorkerInstance, getSuspendedInstances, findInstanceById, clearSuspension, createInstance } from "../types/instance.js";
import { userMessage, isInstanceMessage } from "../types/messages.js";
import { isResume } from "../types/commands.js";


/** Check if packStates has any entries */
const hasPackStates = (ps?: Record<string, unknown>): boolean =>
  ps !== undefined && Object.keys(ps).length > 0;

// ============================================================================
// Parallel Execution Helpers
// ============================================================================

/**
 * Result from a single leaf execution.
 * With the new message-passing flow, the executor enqueues messages directly
 * and returns only the yield reason.
 */
export interface LeafResult {
  /** Index path to this leaf in the tree */
  leafIndex: number[];
  /** Whether this is a worker instance */
  isWorker: boolean;
  /** Instance ID for attribution */
  instanceId: string;
  /** Why this leaf yielded */
  yieldReason: YieldReason;
}

/**
 * @deprecated Use LeafResult instead. This interface is kept for backwards compatibility.
 * Legacy result type that includes instance and history (now handled via message queue).
 */
export interface LegacyLeafResult<AppMessage = unknown> extends LeafResult {
  /** Updated instance from executor */
  instance: Instance;
  /** History generated by this leaf */
  history: MachineMessage<AppMessage>[];
  /** Updated pack states (only from non-worker) */
  packStates?: Record<string, unknown>;
  /** Cede content if yielded via cede (string or MachineMessage[]) */
  cedeContent?: string | MachineMessage<AppMessage>[];
}

/**
 * @deprecated Use drainQueue + applyInstanceMessages instead.
 * This interface is kept for backwards compatibility with voice package.
 */
export interface MergedResult<AppMessage = unknown> {
  /** Updated instance tree */
  instance: Instance;
  /** All history from all leaves */
  history: MachineMessage<AppMessage>[];
  /** Overall yield reason (tool_use if any leaf needs more work) */
  yieldReason: YieldReason;
  /** Whether any leaf ceded */
  hasCede: boolean;
  /** Cede contents from ceded leaves */
  cedeContents: Array<{ instanceId: string; content: string | MachineMessage<AppMessage>[] | undefined }>;
}

/**
 * Update a leaf instance at the given index path.
 */
function updateLeafAtIndex(
  root: Instance,
  indices: number[],
  updater: (leaf: Instance) => Instance,
): Instance {
  if (indices.length === 0) return updater(root);

  const [head, ...rest] = indices;
  const children = root.children ?? [];
  const updated = children.map((c, i) => i === head ? updateLeafAtIndex(c, rest, updater) : c);

  return {
    ...root,
    children: updated.length === 0 ? undefined : updated,
  };
}

/**
 * Remove a leaf instance at the given index path.
 */
function removeLeafAtIndex(root: Instance, indices: number[]): Instance {
  const children = root.children ?? [];

  if (indices.length === 1) {
    const [idx] = indices;
    const filtered = children.filter((_, i) => i !== idx);
    return {
      ...root,
      children: filtered.length === 0 ? undefined : filtered,
    };
  }

  const [head, ...rest] = indices;
  const updated = children.map((c, i) => i === head ? removeLeafAtIndex(c, rest) : c);

  return {
    ...root,
    children: updated.length === 0 ? undefined : updated,
  };
}

/**
 * Wrap messages with source instance metadata.
 */
function wrapMessages<AppMessage>(
  messages: MachineMessage<AppMessage>[],
  instanceId: string,
): MachineMessage<AppMessage>[] {
  return messages.map(msg => {
    const existing = msg.metadata;
    const existingSource = existing?.source;
    if (existingSource?.instanceId && existingSource.instanceId !== instanceId) {
      console.warn(
        `[wrapMessages] Overwriting source.instanceId: ${existingSource.instanceId} -> ${instanceId}`
      );
    }
    const newSource: MessageSource = { ...existingSource, instanceId };
    return {
      ...msg,
      metadata: { ...existing, source: newSource },
    };
  }) as MachineMessage<AppMessage>[];
}

/**
 * Update an instance in the tree by ID.
 */
function updateInstanceById(
  root: Instance,
  targetId: string,
  updater: (inst: Instance) => Instance,
): Instance {
  if (root.id === targetId) {
    return updater(root);
  }

  const children = root.children;
  if (!children || children.length === 0) {
    return root;
  }

  return {
    ...root,
    children: children.map((c) => updateInstanceById(c, targetId, updater)),
  };
}

/**
 * Remove an instance from the tree by ID.
 * Returns the updated tree, or the original if not found.
 */
function removeInstanceById(root: Instance, targetId: string): Instance {
  // Can't remove root
  if (root.id === targetId) {
    console.warn(`[removeInstanceById] Cannot remove root instance ${targetId}`);
    return root;
  }

  const children = root.children;
  if (!children || children.length === 0) {
    return root;
  }

  // Check if any direct child matches
  const filtered = children.filter((c) => c.id !== targetId);
  if (filtered.length !== children.length) {
    // Found and removed
    return {
      ...root,
      children: filtered.length === 0 ? undefined : filtered,
    };
  }

  // Recurse into children
  return {
    ...root,
    children: children.map((c) => removeInstanceById(c, targetId)),
  };
}

// ============================================================================
// Queue Drain & Apply Logic
// ============================================================================

/**
 * Result of draining the queue.
 */
export interface DrainResult<AppMessage = unknown> {
  /** Instance mutation messages (applied to machine.instance) */
  instanceMessages: InstanceMessage<AppMessage>[];
  /** Conversation messages (user, assistant, system, command) for history */
  conversationMessages: ConversationMessage<AppMessage>[];
}

/**
 * Drain all messages from the machine queue into categorized buckets.
 * This empties the queue and returns messages partitioned by type.
 */
export function drainQueue<AppMessage = unknown>(
  machine: Machine<AppMessage>,
): DrainResult<AppMessage> {
  const messages = machine.queue.splice(0, machine.queue.length);

  const instanceMessages: InstanceMessage<AppMessage>[] = [];
  const conversationMessages: ConversationMessage<AppMessage>[] = [];

  for (const msg of messages) {
    if (isInstanceMessage(msg)) {
      instanceMessages.push(msg);
    } else {
      // user, assistant, system, command - all go to conversation history
      conversationMessages.push(msg as ConversationMessage<AppMessage>);
    }
  }

  return { instanceMessages, conversationMessages };
}

/**
 * Apply instance messages to the machine's instance tree.
 * Uses shallow merge for state updates, last-write-wins with warnings for duplicates.
 *
 * @param machine - The machine to update
 * @param instanceMessages - Instance messages to apply
 * @param stepNumber - Current step number for logging
 * @returns Object with hasCede flag and any cede contents
 */
export function applyInstanceMessages<AppMessage = unknown>(
  machine: Machine<AppMessage>,
  instanceMessages: InstanceMessage<AppMessage>[],
  stepNumber: number,
): {
  hasCede: boolean;
  cedeContents: Array<{ instanceId: string; content: string | MachineMessage<AppMessage>[] | undefined }>;
} {
  // Track writes for duplicate detection
  const stateWrites = new Map<string, number>(); // instanceId -> write count
  const packStateWrites = new Map<string, number>(); // packName -> write count

  const cedeContents: Array<{ instanceId: string; content: string | MachineMessage<AppMessage>[] | undefined }> = [];
  let hasCede = false;

  for (const msg of instanceMessages) {
    const payload = msg.items;

    switch (payload.kind) {
      case "state": {
        // Track duplicate writes
        const count = (stateWrites.get(payload.instanceId) ?? 0) + 1;
        stateWrites.set(payload.instanceId, count);
        if (count > 1) {
          console.warn(
            `[runMachine] Step ${stepNumber}: instanceId ${payload.instanceId} state updated ${count} times, last write wins`
          );
        }

        // Shallow merge into instance state
        machine.instance = updateInstanceById(
          machine.instance,
          payload.instanceId,
          (inst) => ({
            ...inst,
            state: { ...(inst.state as Record<string, unknown>), ...payload.patch },
          }),
        );
        break;
      }

      case "packState": {
        // Track duplicate writes
        const count = (packStateWrites.get(payload.packName) ?? 0) + 1;
        packStateWrites.set(payload.packName, count);
        if (count > 1) {
          console.warn(
            `[runMachine] Step ${stepNumber}: packState ${payload.packName} updated ${count} times, last write wins`
          );
        }

        // Shallow merge into pack state on root
        const currentPackStates = machine.instance.packStates ?? {};
        const currentPackState = currentPackStates[payload.packName] as Record<string, unknown> | undefined;
        machine.instance = {
          ...machine.instance,
          packStates: {
            ...currentPackStates,
            [payload.packName]: { ...currentPackState, ...payload.patch },
          },
        };
        break;
      }

      case "transition": {
        // Replace node/state, clear children
        machine.instance = updateInstanceById(
          machine.instance,
          payload.instanceId,
          (inst) => ({
            ...inst,
            node: payload.node,
            state: payload.state ?? payload.node.initialState,
            children: undefined,
            executorConfig: payload.executorConfig ?? payload.node.executorConfig,
          }),
        );
        break;
      }

      case "spawn": {
        // Add children to parent instance
        const newChildren = payload.children.map(({ node, state, executorConfig }) =>
          createInstance(
            node,
            state ?? node.initialState,
            undefined,
            undefined,
            executorConfig ?? node.executorConfig,
          ),
        );

        machine.instance = updateInstanceById(
          machine.instance,
          payload.parentInstanceId,
          (inst) => ({
            ...inst,
            children: [...(inst.children ?? []), ...newChildren],
          }),
        );
        break;
      }

      case "cede": {
        // Remove instance from tree
        machine.instance = removeInstanceById(machine.instance, payload.instanceId);
        cedeContents.push({ instanceId: payload.instanceId, content: payload.content });
        hasCede = true;
        break;
      }

      case "suspend": {
        // Mark instance as suspended
        machine.instance = updateInstanceById(
          machine.instance,
          payload.instanceId,
          (inst) => ({
            ...inst,
            suspended: payload.suspendInfo,
          }),
        );
        break;
      }
    }
  }

  return { hasCede, cedeContents };
}

/**
 * @deprecated Use drainQueue + applyInstanceMessages instead.
 * Merge results from parallel leaf execution.
 * Processes in descending index order so removals don't invalidate later indices.
 * Exported for use by voice package.
 */
export function mergeLeafResults<AppMessage>(
  root: Instance,
  results: LegacyLeafResult<AppMessage>[],
): MergedResult<AppMessage> {
  let instance = root;
  const allMessages: MachineMessage<AppMessage>[] = [];
  const cedeContents: Array<{ instanceId: string; content: string | MachineMessage<AppMessage>[] | undefined }> = [];
  let hasCede = false;
  let overallYieldReason: YieldReason = "end_turn";
  const packStateUpdates: Record<string, unknown> = {};

  // Sort descending by leaf index (process later/deeper indices first)
  const sorted = [...results].sort((a, b) => {
    for (let i = Math.max(a.leafIndex.length, b.leafIndex.length) - 1; i >= 0; i--) {
      if ((a.leafIndex[i] ?? -1) !== (b.leafIndex[i] ?? -1)) {
        return (b.leafIndex[i] ?? -1) - (a.leafIndex[i] ?? -1);
      }
    }
    return 0;
  });

  for (const leaf of sorted) {
    const { leafIndex, isWorker, instanceId, history, yieldReason, packStates, cedeContent } = leaf;

    // Only non-worker can update pack states
    // Note: Only one non-worker leaf can exist at a time (validated at lines 439-445),
    // so pack state conflicts between leaves cannot occur. This assignment is safe.
    if (!isWorker && packStates) {
      Object.assign(packStateUpdates, packStates);
    }

    // Worker end_turn without cede -> warning (but don't propagate as machine end_turn)
    if (isWorker && yieldReason === "end_turn") {
      console.warn(
        `[runMachine] Worker instance ${instanceId} returned end_turn without ceding. ` +
        `This is unexpected - worker nodes should cede to return control to parent. ` +
        `Treating as if worker work is complete (not propagating end_turn to machine).`
      );
      // Continue processing - don't let worker end_turn affect machine state
      continue;
    }

    // Cede -> remove leaf
    if (yieldReason === "cede") {
      instance = removeLeafAtIndex(instance, leafIndex);
      cedeContents.push({ instanceId, content: cedeContent });
      allMessages.push(...wrapMessages(history, instanceId));
      hasCede = true;
      continue;
    }

    // Normal -> update leaf
    instance = updateLeafAtIndex(instance, leafIndex, () => leaf.instance);
    allMessages.push(...wrapMessages(history, instanceId));

    if (yieldReason === "tool_use" || yieldReason === "max_tokens") {
      overallYieldReason = "tool_use";
    }
  }

  // Apply pack states to root
  if (Object.keys(packStateUpdates).length > 0) {
    instance = { ...instance, packStates: { ...instance.packStates, ...packStateUpdates } };
  }

  return { instance, history: allMessages, yieldReason: overallYieldReason, hasCede, cedeContents };
}

/**
 * Run the machine by draining its queue and executing.
 * Yields MachineStep for each inference call or command execution.
 * Continues until there's a text response or max steps exceeded.
 *
 * Use machine.enqueue() to add messages before calling runMachine:
 * - Regular messages (user, assistant) are added to history and sent to the model
 * - Command messages are processed with higher precedence
 * - Instance messages describe mutations to the instance tree
 * - System messages (with Resume) are used for internal control flow
 *
 * @typeParam AppMessage - The application message type for structured outputs (defaults to unknown).
 */
export async function* runMachine<AppMessage = unknown>(
  machine: Machine<AppMessage>,
  options?: RunOptions<AppMessage>,
): AsyncGenerator<MachineStep<AppMessage>> {
  // Initial drain of queue
  const initialDrain = drainQueue(machine);

  // Check for Resume in system messages
  for (const msg of initialDrain.conversationMessages) {
    if (msg.role === "system" && Array.isArray(msg.items)) {
      const resumeItem = msg.items.find(isResume) as Resume | undefined;
      if (resumeItem) {
        // Process Resume
        const targetInstance = findInstanceById(machine.instance, resumeItem.instanceId);
        if (!targetInstance) {
          throw new Error(`Instance not found: ${resumeItem.instanceId}`);
        }
        if (!targetInstance.suspended) {
          throw new Error(`Instance ${resumeItem.instanceId} is not suspended`);
        }
        if (targetInstance.suspended.suspendId !== resumeItem.suspendId) {
          throw new Error(
            `Suspend ID mismatch: expected ${targetInstance.suspended.suspendId}, got ${resumeItem.suspendId}`
          );
        }

        // Clear the suspended field
        machine.instance = updateInstanceById(
          machine.instance,
          resumeItem.instanceId,
          clearSuspension,
        );

        const stepHistory: MachineMessage<AppMessage>[] = [userMessage(`[Resumed instance ${resumeItem.instanceId}]`)];
        machine.history = [...machine.history, ...stepHistory];

        yield {
          instance: machine.instance,
          history: stepHistory,
          yieldReason: "command",
          done: false,
        };
        return;
      }
    }
  }

  // Add initial conversation messages to machine.history
  machine.history = [...machine.history, ...initialDrain.conversationMessages];

  // Apply any initial instance messages
  applyInstanceMessages(machine, initialDrain.instanceMessages, 0);

  // Check if we should skip leaf execution (only silent user messages)
  const hasNonSilentUserMessage = initialDrain.conversationMessages.some(
    msg => msg.role === "user" && msg.metadata?.silent !== true
  );

  if (!hasNonSilentUserMessage) {
    // All processing done (history updated, instance messages applied)
    // Yield step without running leaves
    yield {
      instance: machine.instance,
      history: [...initialDrain.conversationMessages, ...initialDrain.instanceMessages],
      yieldReason: "end_turn",
      done: true,
    };
    return;
  }

  const maxSteps = options?.maxSteps ?? 50;
  let steps = 0;
  let tokenRecoveryAttempted = false;

  while (steps < maxSteps) {
    steps++;

    // Get all active leaves for parallel execution
    const activeLeaves = getActiveLeaves(machine.instance);
    if (activeLeaves.length === 0) {
      // Check if all leaves are suspended
      const suspendedInstances = getSuspendedInstances(machine.instance);
      if (suspendedInstances.length > 0) {
        // All leaves are suspended - yield awaiting_resume
        const suspendedInfo: SuspendedInstanceInfo[] = suspendedInstances.map((inst) => ({
          instanceId: inst.id,
          suspendId: inst.suspended!.suspendId,
          reason: inst.suspended!.reason,
          metadata: inst.suspended!.metadata,
        }));
        yield {
          instance: machine.instance,
          history: [],
          yieldReason: "awaiting_resume",
          done: true,
          suspendedInstances: suspendedInfo,
        };
        return;
      }
      throw new Error("No active instances found");
    }

    // Validate: max 1 non-worker leaf
    const nonWorkerLeaves = activeLeaves.filter(l => !l.isWorker);
    if (nonWorkerLeaves.length > 1) {
      console.log(nonWorkerLeaves)
      throw new Error(
        `Invalid state: ${nonWorkerLeaves.length} non-worker active leaves. ` +
        `At most one instance can receive user input per step.`
      );
    }

    if (options?.debug) {
      console.log(`[runMachine] Step ${steps}/${maxSteps}`);
      console.log(`[runMachine]   Active leaves: ${activeLeaves.length} (${nonWorkerLeaves.length} non-worker)`);
    }

    // Execute all leaves in parallel - they enqueue messages directly
    const results = await Promise.all(
      activeLeaves.map(async ({ path, leafIndex, isWorker }) => {
        const leaf = path[path.length - 1]!;
        const ancestors = path.slice(0, -1);

        if (options?.debug) {
          const instructions = leaf.node.instructions;
          console.log(`[runMachine]   Leaf ${leafIndex.join('.')}: ${instructions.slice(0, 40)}... (worker: ${isWorker})`);
        }

        const result = await machine.charter.executor.run(
          machine.charter,
          leaf,
          ancestors,
          "",
          {
            ...options,
            history: machine.history,
            currentStep: steps,
            maxSteps,
            enqueue: machine.enqueue,
            instanceId: leaf.id,
            isWorker,
          },
        );

        return {
          leafIndex,
          isWorker,
          instanceId: leaf.id,
          yieldReason: result.yieldReason,
        };
      })
    );

    if (options?.debug) {
      for (const r of results) {
        console.log(`[runMachine]   Leaf ${r.leafIndex.join('.')} result: ${r.yieldReason}`);
      }
    }

    // Drain the queue to collect step history and apply instance changes
    const stepDrain = drainQueue(machine);

    // Apply instance messages and collect cede info
    const { hasCede, cedeContents } = applyInstanceMessages(machine, stepDrain.instanceMessages, steps);

    // Step history is all conversation messages from this step
    const stepHistory: MachineMessage<AppMessage>[] = [...stepDrain.conversationMessages];

    // Add step history to machine.history (includes instance messages for future reference)
    machine.history = [
      ...machine.history,
      ...stepDrain.conversationMessages,
      ...stepDrain.instanceMessages,
    ];

    // Determine primary yield reason (from non-worker leaf)
    const primaryResult = results.find(r => !r.isWorker);
    const primaryYieldReason = primaryResult?.yieldReason ?? "end_turn";

    // Check for worker end_turn without cede (warning)
    for (const r of results) {
      if (r.isWorker && r.yieldReason === "end_turn") {
        console.warn(
          `[runMachine] Worker instance ${r.instanceId} returned end_turn without ceding. ` +
          `This is unexpected - worker nodes should cede to return control to parent.`
        );
      }
      if (r.isWorker && r.yieldReason === "tool_use" && primaryYieldReason === "end_turn") {
        console.warn(
          `[runMachine] Warning: Worker ${r.instanceId} has yieldReason=tool_use but primary ended turn. Worker work abandoned.`
        );
      }
    }

    // Handle cede
    if (hasCede) {
      const cedeInfo = cedeContents[0];
      const cedeContent = cedeInfo?.content;

      // Add cede content as user message for parent context
      if (cedeContent !== undefined) {
        if (typeof cedeContent === "string") {
          const cedeMessage = userMessage<AppMessage>(cedeContent, { source: { instanceId: cedeInfo!.instanceId } });
          machine.history = [...machine.history, cedeMessage];
        } else {
          machine.history = [...machine.history, ...cedeContent];
        }
      }

      // If single-leaf cede, yield explicit cede step
      if (activeLeaves.length === 1) {
        yield {
          instance: machine.instance,
          history: stepHistory,
          yieldReason: "cede",
          done: false,
          cedeContent,
        };
        continue;
      }
    }

    // Handle max_tokens recovery for primary leaf
    if (primaryYieldReason === "max_tokens") {
      if (!tokenRecoveryAttempted) {
        tokenRecoveryAttempted = true;
        if (options?.debug) {
          console.log(`[runMachine] max_tokens hit, attempting recovery...`);
        }

        // Yield the partial step (not final)
        yield {
          instance: machine.instance,
          history: stepHistory,
          yieldReason: "max_tokens",
          done: false,
        };

        // Add recovery message
        const recoveryMessage = userMessage<AppMessage>(
          `[System: Your response was cut off due to length limits. Please provide a brief summary of your findings and respond to the user now. Do not use any tools - just give your final answer.]`
        );
        machine.history = [...machine.history, recoveryMessage];
        continue;
      } else {
        // Recovery already attempted, treat as final
        yield {
          instance: machine.instance,
          history: stepHistory,
          yieldReason: "max_tokens",
          done: true,
        };
        return;
      }
    }

    // Determine if step is final based on primary yield reason
    // "end_turn" = LLM finished responding
    // "external" = inference delegated to external system (e.g., LiveKit voice)
    const isFinal = primaryYieldReason === "end_turn" || primaryYieldReason === "external";

    yield {
      instance: machine.instance,
      history: stepHistory,
      yieldReason: primaryYieldReason,
      done: isFinal,
    };

    if (isFinal) {
      return;
    }
  }

  throw new Error(`Max steps (${maxSteps}) exceeded`);
}

/**
 * Run the machine to completion, returning only the final step.
 * Convenience wrapper for cases that don't need step-by-step control.
 *
 * @typeParam AppMessage - The application message type for structured outputs (defaults to unknown).
 */
export async function runMachineToCompletion<AppMessage = unknown>(
  machine: Machine<AppMessage>,
  options?: RunOptions<AppMessage>,
): Promise<MachineStep<AppMessage>> {
  let lastStep: MachineStep<AppMessage> | null = null;
  for await (const step of runMachine(machine, options)) {
    lastStep = step;
  }
  if (!lastStep) {
    throw new Error("No steps produced");
  }
  return lastStep;
}
